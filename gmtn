#!/usr/bin/env python3
# Anchor extraction from HTML document
import sys
import time
from bs4 import BeautifulSoup
from urllib.request import urlopen

def reveal_sources(source_file):
    for line in source_file:
        print("Getting links from " + line + "...")
        parse_for_links(line)

def parse_for_links(site):
    with urlopen(site) as response:
        soup = BeautifulSoup(response, 'html.parser')
        for anchor in soup.find_all('a'):
            print(anchor.get('href', '/'))

# for no options, I probably want to parse for common words somehow
# Probably should use like... a hashmap? Or something?
# I need to think of the algorithm for this -- how to pull out important words.
# maybe cross reference words in URLs on the page, too. Since those will probably
# contain keywords

def main(argv):
    sources_path = "./sources/" + str(sys.argv[1])
    fp = open(sources_path, 'r')
    reveal_sources(fp)
    fp.close()

if __name__ == "__main__":
    main(sys.argv[1:])

